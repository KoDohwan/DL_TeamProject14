{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from resnet import ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available() == True:\n",
    "    device = torch.device('cuda:0')\n",
    "    print(torch.cuda.get_device_name())\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4), transforms.RandomHorizontalFlip(), \n",
    "                                transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "transform_test = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "bar_format = '{bar:30} {n_fmt}/{total_fmt} [{elapsed}<{remaining} {rate_fmt}] {desc}'\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.cifar.CIFAR10'>\n"
     ]
    }
   ],
   "source": [
    "print(type(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img[0] = img[0] * 0.2023 + 0.4914\n",
    "    img[1] = img[1] * 0.1994 + 0.4822\n",
    "    img[2] = img[2] * 0.2010 + 0.4465\n",
    "    npimg = img.cpu().detach().numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(epoch, acc, optimizer):\n",
    "    global best_acc\n",
    "    if acc > best_acc:\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f'./models/model_{epoch}.pth')\n",
    "        best_acc = acc\n",
    "        print('Saving Model...')\n",
    "\n",
    "def load_model(name):\n",
    "    state_dict = torch.load(f'./models/{name}.pth', map_location=device)\n",
    "    model = ResNet18()\n",
    "    model.to(device)\n",
    "    model.load_state_dict(state_dict['model'])\n",
    "    optimizer = optim.SGD(model.parameters(), lr=1e-1, momentum=0.9, weight_decay=1e-4)\n",
    "#     optimizer.load_state_dict(state_dict['optimizer'])\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    perturbed_image = image + epsilon * sign_data_grad\n",
    "#     perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack(model, epsilon):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    success = 0\n",
    "    total = 0\n",
    "    test_iter = tqdm(enumerate(test_loader), total=len(test_loader), unit_scale=batch_size, bar_format=bar_format)\n",
    "    for i, (batch, label) in test_iter:\n",
    "        batch, label = batch.to(device), label.to(device)\n",
    "        batch.requires_grad = True\n",
    "        output = model(batch)\n",
    "        loss = loss_function(output, label)\n",
    "        _, predicted = output.max(1)\n",
    "        \n",
    "        model.zero_grad() #Note to my self:\n",
    "                          #IF all your model parameters are in that optimizer,\n",
    "                          #model.zero_grad() and optimizer.zero_grad() are the same \n",
    "        loss.backward()\n",
    "        batch_grad = batch.grad.data #Derive gradient value w.r.t each data instance(in the batch)\n",
    "        for i, data in enumerate(batch.clone()): \n",
    "            if label[i].item() == predicted[i].item():\n",
    "                data_grad = batch_grad[i]\n",
    "                perturbed_image = fgsm_attack(data, epsilon, data_grad)\n",
    "                batch[i] = perturbed_image\n",
    "\n",
    "            else:\n",
    "                batch[i] = data\n",
    "        \n",
    "        new_output = model(batch)\n",
    "        _, new_predicted = new_output.max(1)\n",
    "        print(\"new_predicted : \" , new_predicted)\n",
    "        print(\"original label : \" , label)\n",
    "        total += label.size(0)\n",
    "        correct += new_predicted.eq(label).sum().item()\n",
    "        success += (~new_predicted.eq(predicted)).sum().item()\n",
    "\n",
    "        acc = 100. * correct / total\n",
    "        test_iter.set_description(f'[{acc:.2f}%({correct}/{total}) {success}]', False)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM Attack\n",
    "model, optimizer = load_model('baseline')\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "epsilon = 0.01\n",
    "attack(model, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_advs(model, epsilon):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    success = 0\n",
    "    total = 0\n",
    "    adv_instances = []\n",
    "    test_iter = tqdm(enumerate(test_loader), total=len(test_loader), unit_scale=batch_size, bar_format=bar_format)\n",
    "    for j, (batch, label) in test_iter:\n",
    "        batch, label = batch.to(device), label.to(device)\n",
    "        batch.requires_grad = True\n",
    "        output = model(batch)\n",
    "        loss = loss_function(output, label)\n",
    "        _, predicted = output.max(1)\n",
    "        \n",
    "        model.zero_grad() #Note to my self:\n",
    "                          #IF all your model parameters are in that optimizer,\n",
    "                          #model.zero_grad() and optimizer.zero_grad() are the same \n",
    "        loss.backward()\n",
    "        batch_grad = batch.grad.data #Derive gradient value w.r.t each data instance(in the batch)\n",
    "        for i, data in enumerate(batch.clone()): \n",
    "            if label[i].item() == predicted[i].item():\n",
    "                data_grad = batch_grad[i]\n",
    "                perturbed_image = fgsm_attack(data, epsilon, data_grad)\n",
    "                #batch[i] = perturbed_image\n",
    "                _, perutb_predict = model(perturbed_image.view(1,3,32,32)).max(1)\n",
    "                #print(\"Output shape\", perutb_predict)\n",
    "                #check perturbed one is also adversarial\n",
    "                if perutb_predict.item() != predicted[i].item():\n",
    "                    adv_instances.append(perturbed_image)\n",
    "        print(\"Collected Adv Instances So far : {}\".format(len(adv_instances)))\n",
    "        if j==2:\n",
    "            print(\"End temp\")\n",
    "            break\n",
    "    return adv_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                               32/10016 [00:04<23:22  7.12it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected Adv Instances So far : 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "▏                              64/10016 [00:08<22:39  7.32it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected Adv Instances So far : 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "▏                              64/10016 [00:12<33:05  5.01it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected Adv Instances So far : 19\n",
      "End temp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# FGSM Attack\n",
    "model, optimizer = load_model('baseline')\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "epsilon = 0.01\n",
    "adv_instances = collect_advs(model, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def slices_advs(adv_colls, shuffle_seed = None, slice_by=5): # '''slice_by씩''' 끊어서 자르기\n",
    "    if not shuffle_seed:\n",
    "        random.Random(shuffle_seed).shuffle(adv_colls)\n",
    "    slices = []\n",
    "    for i in range(0,len(adv_colls),slice_by):\n",
    "        slices.append(adv_colls[i:i+slice_by])\n",
    "    return slices \n",
    "\n",
    "slices = slices_advs(adv_instances)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "##forming custom dataset only of adv instances\n",
    "from torch.utils.data import Dataset, ConcatDataset\n",
    "class AdvDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, adv_instances):\n",
    "        self.adv_instances = adv_instances\n",
    "    def __len__(self):\n",
    "        return len(self.adv_instances)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.adv_instances[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.ConcatDataset at 0x129ee8580>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConcatDataset([AdvDataSet(adv_instances),trainset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final packaging function\n",
    "def advaug_datasets(original_dataset, adv_col_slices): #original_dataset: 원래 데이터셋, torch.tuils.data.Dataset\n",
    "                                                        #adv_col_slices: lists of list of adveseiral instances(slices_advs output)\n",
    "    datasets = []\n",
    "    for i in range(len(adv_col_slices)):\n",
    "        dataset = ConcatDataset([AdvDataSet(adv_col_slices[i]),trainset])\n",
    "        datasets.append(dataset)\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.utils.data.dataset.ConcatDataset at 0x129ee8ee0>,\n",
       " <torch.utils.data.dataset.ConcatDataset at 0x129ee83a0>,\n",
       " <torch.utils.data.dataset.ConcatDataset at 0x129ee8c70>,\n",
       " <torch.utils.data.dataset.ConcatDataset at 0x129ee8430>]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advaug_datasets(trainset, slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
